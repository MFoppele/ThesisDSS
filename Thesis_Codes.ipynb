{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMP: Export file.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDn7aYPBFTxO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FYPTEtKczUn"
      },
      "source": [
        "!pip install lexicalrichness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBqfR7fkcpWn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from statistics import mean\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from lexicalrichness import LexicalRichness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge_M5N8XphDA"
      },
      "source": [
        "!pip install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObutG6hEpio5"
      },
      "source": [
        "!pip install OpenNMT-py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMH8bfnDpj37"
      },
      "source": [
        "!pip install sacremoses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r9oESgqXmRE"
      },
      "source": [
        "MYCLASSFOLDER=\"DSS_Thesis_code\"\n",
        "import os\n",
        "os.environ['PATH'] += \":/content/drive/MyDrive/\" + MYCLASSFOLDER + \"/scripts\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-n1SulKX00d"
      },
      "source": [
        "!MYCLASSFOLDER=\"DSS_Thesis_code\"\n",
        "!mkdir /content/drive/MyDrive/$MYCLASSFOLDER/\n",
        "!ls /content/drive/MyDrive/$MYCLASSFOLDER"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfXRCYhFYxR4"
      },
      "source": [
        "cd /content/drive/MyDrive/$MYCLASSFOLDER"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2FyyxD8pBYw"
      },
      "source": [
        "!wget https://ilk.uvt.nl/~shterion/scripts/bpe.sh -O scripts/bpe.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ab6UWJsvrYp"
      },
      "source": [
        "!mkdir scripts #Make folder with 'scripts'\n",
        "!wget https://ilk.uvt.nl/~shterion/scripts/train_test_dev.py -O scripts/train_test_dev.py\n",
        "!wget https://ilk.uvt.nl/~shterion/scripts/bpe.sh -O scripts/bpe.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKOBMZxZwKny"
      },
      "source": [
        "#!wget https://ilk.uvt.nl/~shterion/scripts/tokenizer.perl -O scripts/tokenizer.perl\n",
        "!wget https://ilk.uvt.nl/~shterion/scripts/detokenize.perl -O scripts/detokenize.perl\n",
        "#!wget https://ilk.uvt.nl/~shterion/scripts/nonbreaking_prefixes.zip -O scripts/nonbreaking_prefixes.zip\n",
        "#!unzip scripts/nonbreaking_prefixes.zip -d scripts/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IsFIo9RwXtJ"
      },
      "source": [
        "!wget https://ilk.uvt.nl/~shterion/data/EN-NL.zip -O EN-NL.zip\n",
        "!unzip -K EN-NL.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oTu50d6ZezL"
      },
      "source": [
        "df = pd.read_excel(r'/content/drive/My Drive/DSS_Thesis_code/Thesis_Data_Merged.xlsx') #Loading the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMcFmtwbcBR_"
      },
      "source": [
        "print(len(df['Spoken'].unique())) #Test to see how long the aligned data set should be"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy05-t2eicjA"
      },
      "source": [
        "data = df.groupby('Spoken')['Sign'].apply(lambda group_series: group_series.tolist()).reset_index() #Allocates all the snippits to their correct counterpart in list format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rz0d65J1HoF"
      },
      "source": [
        "for index in range(len(data['Sign'])):\n",
        "  data['Sign'][index] = [word for word in data['Sign'][index] if not(pd.isnull(word)) == True] #Removing all the nan's from the data using help from https://www.pythonpool.com/python-remove-nan-from-list/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xztjz4jW2BA6"
      },
      "source": [
        "for index in range(len(data['Sign'])):\n",
        "  data['Sign'][index] = ' '.join([str(i) for i in data['Sign'][index]]) #Transforms the lists into strings "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GgaqjTB7UXj"
      },
      "source": [
        "for index in range(len(data['Spoken'])):\n",
        "  data['Spoken'][index] = data['Spoken'][index].replace('ß', 'ss') #Replacing all the 'ß' with 'ss' in the Spoken column\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs3sS5A9fBCb"
      },
      "source": [
        "for index in range(len(data['Sign'])):\n",
        "  data['Sign'][index] = data['Sign'][index].replace('ß', 'ss') #Replacing all the 'ß' with 'ss' in the Sign column (just to be sure)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7CRpKQAJVZU"
      },
      "source": [
        "nltk.download('stopwords') #Import all stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98zBhfjqPqQY"
      },
      "source": [
        "sw = stopwords.words('german')#Import all German stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo8LB-NpJ5IR"
      },
      "source": [
        "def compression(data):\n",
        "    word = data.split()\n",
        "    return ' '.join([z for z in word if not z in sw])\n",
        "\n",
        "\n",
        "data['Compressed']  = data['Spoken'].apply(compression) #apply compression function to data  https://stackoverflow.com/questions/57374542/i-want-to-remove-all-the-german-stop-words-from-data-set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLc6QS7gSTrO"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUaF--dysJ14"
      },
      "source": [
        "source = data['Sign']\n",
        "target = data['Spoken']\n",
        "target_compressed = data['Compressed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q_i7HtWa6-f"
      },
      "source": [
        "comp = []\n",
        "nor = []\n",
        "for i in range(len(target_compressed)):\n",
        "  comp.append(len(target_compressed[i]))\n",
        "for z in range(len(target)):\n",
        "  nor.append(len(target[z]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WA5ws5h6TXn"
      },
      "source": [
        "ratios = []\n",
        "for d in range(len(comp)):\n",
        "  ratios.append(comp[d]/nor[d])\n",
        "compression_metric = mean(ratios)\n",
        "print(compression_metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOe7JWPQtHqI"
      },
      "source": [
        "if len(df['Spoken'].unique()) -1 == len(source) and len(df['Spoken'].unique()) -1 == len(target) and len(df['Spoken'].unique()) -1 == len(target_compressed):\n",
        "  with open('source.en','w') as writefile:\n",
        "          for line in source:\n",
        "                writefile.writelines(line + '\\n')\n",
        "  with open('target.de','w') as writefile:\n",
        "          for line in target:\n",
        "                writefile.writelines(line + '\\n')\n",
        "  with open('target_compressed.de','w') as writefile:\n",
        "          for line in target_compressed:\n",
        "                writefile.writelines(line + '\\n')\n",
        "else:\n",
        "  print('Error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTR40bYJ7AyS"
      },
      "source": [
        "!ls -l\n",
        "!perl scripts/tokenizer.perl -no-escape -l de -threads 16 < target.de > target.tok.de\n",
        "!perl scripts/tokenizer.perl -no-escape -l de -threads 16 < target_compressed.de > target_compressed.tok.de"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "681gczJ58RpG"
      },
      "source": [
        "%run scripts/train_test_dev.py --source=source.en --target=target.tok.de "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkjjaSmG1mWz"
      },
      "source": [
        "!pip install subword-nmt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4eBisNB10hV"
      },
      "source": [
        "!subword-nmt learn-bpe -s 50000 < train.tok.clean.trg > bpe.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpL81-Xg3VZ5"
      },
      "source": [
        "!subword-nmt apply-bpe -c bpe.trg < train.tok.clean.trg > train.tok.clean.bpe.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTr2bS-t3ZeN"
      },
      "source": [
        "!subword-nmt apply-bpe -c bpe.trg < test.tok.clean.trg > test.tok.clean.bpe.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX4tX84F3Zon"
      },
      "source": [
        "!subword-nmt apply-bpe -c bpe.trg < dev.tok.clean.trg > dev.tok.clean.bpe.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfPI0C315rAP"
      },
      "source": [
        "%run scripts/train_test_dev.py --source=source.en --target=target_compressed.tok.de "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11H8oG7e8Ir-"
      },
      "source": [
        "!subword-nmt apply-bpe -c bpe.trg < train.tok.clean.trg > train_compressed.tok.clean.bpe.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogi5wJkg8Iwb"
      },
      "source": [
        "!subword-nmt apply-bpe -c bpe.trg < test.tok.clean.trg > test_compressed.tok.clean.bpe.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnUBdB1-8I0q"
      },
      "source": [
        "!subword-nmt apply-bpe -c bpe.trg < dev.tok.clean.trg > dev_compressed.tok.clean.bpe.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvfRGVZv2mRr"
      },
      "source": [
        "#!wc -l bpe.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgGHjSidp-8e"
      },
      "source": [
        "#!onmt_build_vocab -config /content/drive/MyDrive/$MYCLASSFOLDER/EN-NL/config/config_vocab_bpe.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbl5IUm_p4qj"
      },
      "source": [
        "#!wc -l /content/drive/MyDrive/$MYCLASSFOLDER/EN-NL/data/vocab.trg\n",
        "#!head /content/drive/MyDrive/$MYCLASSFOLDER/EN-NL/data/vocab.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyddjYKFbYuU"
      },
      "source": [
        "#%run scripts/train_test_dev.py --source=source.en --target=target_compressed.tok.de "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1QbDhl65iWf"
      },
      "source": [
        "def ttr_mattr(x):\n",
        "  text = \"\"\"\"\"\"\n",
        "  for i in x:\n",
        "    text += i \n",
        "  lexc = LexicalRichness(text)\n",
        "\n",
        "  ttr_c = lexc.ttr\n",
        "  mattr_c = lexc.mattr\n",
        "  print('TTR =', round(ttr_c, 3), 'MATTR =', round(mattr_c(25), 3))\n",
        "  return(round(ttr_c, 3), round(mattr_c(25), 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9HzLR_U82jb"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Baseline/test.tok.clean.bpe.trg','r') as r: #DGS corpus normal\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPfD6cOwMRMf"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/lstm_baseline_final.txt','r') as r: #Baseline LSTM output\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rHQ6lswMRPo"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/trans_baseline_final.txt','r') as r: #Baseline Transformer output\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugY4cHxjMRJf"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Pipeline/test_compressed.tok.clean.bpe.trg','r') as r: #DGS corpus compressed\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ial6XfQvMVXi"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Pipeline1_lstm_translation (modded)','r') as r: #Pipeline LSTM output 1\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JnyqfbWMVyA"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/lstm_pipeline_final.txt','r') as r: #Pipeline LSTM output 2\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNKhpqVr7S97"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Pipeline1_trans_translation (modded)','r') as r: #Pipeline Transformer output 1\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q80gfrvW7UVf"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/trans_pipeline_final.txt','r') as r: #Pipeline Transformer output 2\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpCNm634Oias"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Baseline_trans_translation_run2','r') as r: #Baseline Transformer run2\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfhhRW3lOild"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Pipeline1_trans_translation_run2','r') as r: #Pipeline1 Transformer run2\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiFJ_wm_Ojij"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Pipeline2_trans_translation_run2','r') as r: #Pipeline2 Transformer run2\n",
        "          ttr_mattr(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeIyrieQYv2C"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Baseline/train.tok.clean.src','r') as r:\n",
        "  count = 0\n",
        "  for i in r:\n",
        "    if len(i) == 1:\n",
        "      count += 1\n",
        "  print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF8_Hmxs-BIR"
      },
      "source": [
        "with open('/content/drive/My Drive/DSS_Thesis_code/Pipeline/train_compressed.tok.clean.bpe.trg','r') as b:\n",
        "          ttr_mattr(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4mkkFHlnh83"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY INDEX IN Baseline/train.tok.clean.src\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/train.tok.clean.src', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  index_list = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      index_list.append(index)\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "\n",
        "     \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/train.tok.clean.src', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt5lpP07cUtX"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY MATCHED INDEX IN Baseline/train.tok.clean.bpe.trg\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/train.tok.clean.bpe.trg', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "  \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/train.tok.clean.bpe.trg', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUtHuKdQdIDc"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY INDEX IN Baseline/test.tok.clean.src\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/test.tok.clean.src', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  index_list = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      index_list.append(index)\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/test.tok.clean.src', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5m75m5QdIJP"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY MATCHED INDEX IN Baseline/test.tok.clean.bpe.trg\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/test.tok.clean.bpe.trg', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "  \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/test.tok.clean.bpe.trg', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kUpkBUEdIL7"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY INDEX IN Baseline/dev.tok.clean.src\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/dev.tok.clean.src', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  index_list = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      index_list.append(index)\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "\n",
        "     \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/dev.tok.clean.src', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJUCiahmdIOe"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY MATCHED INDEX IN Baseline/train.tok.clean.bpe.trg\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/dev.tok.clean.bpe.trg', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "  \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline/dev.tok.clean.bpe.trg', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecBARj21dITe"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY INDEX IN Baseline/train.tok.clean.src\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/train.tok.clean.src', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  index_list = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      index_list.append(index)\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "\n",
        "     \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/train.tok.clean.src', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwFZcph0bel_"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY MATCHED INDEX IN Baseline/train.tok.clean.bpe.trg\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/train_compressed.tok.clean.bpe.trg', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "  \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/train_compressed.tok.clean.bpe.trg', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAoBLJ8tfBmH"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY INDEX IN Baseline/test.tok.clean.src\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/test.tok.clean.src', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  index_list = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      index_list.append(index)\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/test.tok.clean.src', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTlLAZZ8fBpK"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY MATCHED INDEX IN Baseline/test.tok.clean.bpe.trg\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/test_compressed.tok.clean.bpe.trg', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "  \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/test_compressed.tok.clean.bpe.trg', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P88ExmXYfBrr"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY INDEX IN Baseline/dev.tok.clean.src\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/dev.tok.clean.src', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  index_list = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      index_list.append(index)\n",
        "for i in reversed(index_list):\n",
        "  del data[i]  \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/dev.tok.clean.src', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3XcDOzEfBuU"
      },
      "source": [
        "#@title\n",
        "#REMOVE EMPTY LINES BY MATCHED INDEX IN Baseline/train.tok.clean.bpe.trg\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/dev_compressed.tok.clean.bpe.trg', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "for i in reversed(index_list):\n",
        "  del data[i]    \n",
        "  \n",
        "\n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline/dev_compressed.tok.clean.bpe.trg', \"w\") as file_object:\n",
        "    for v in data:\n",
        "      file_object.writelines(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDw-j9QlfBw4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhaR0abI-3tc"
      },
      "source": [
        "!onmt_build_vocab -config /content/drive/MyDrive/DSS_Thesis_code/config_vocab_bpe_baseline.yaml #create vocab based on the baseline data set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndo58-OyK6w6"
      },
      "source": [
        "!wc -l /content/drive/MyDrive/DSS_Thesis_code/data/vocab.trg\n",
        "!head /content/drive/MyDrive/DSS_Thesis_code/data/vocab.trg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz-Q4r8ZLKMO"
      },
      "source": [
        "!onmt_train -config /content/drive/MyDrive/DSS_Thesis_code/config_train_lstm_bpe_baseline.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9G0rRO3dKsw"
      },
      "source": [
        "#Peak validation accuracy at 24k steps "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9xXx02aVr4N"
      },
      "source": [
        "!onmt_build_vocab -config /content/drive/MyDrive/DSS_Thesis_code/config_vocab_bpe_pipeline.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "objs0HeRVsAh"
      },
      "source": [
        "!onmt_train -config /content/drive/MyDrive/DSS_Thesis_code/config_train_lstm_bpe_pipeline.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjWLPYFnVsH0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV6O3_OpfTxU"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_lstm_translation', encoding = \"utf-8\") as z: #REMOVE WHITELINES\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(4768, len(data) ):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "  for a in new:\n",
        "    print(a)\n",
        "  \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_lstm_translation', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqttjCfKrDnI"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_trans_translation', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "  for a in new:\n",
        "    print(a)\n",
        "  \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_trans_translation', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oer_aatQa7d3"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline_trans_translation', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline_trans_translation', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP9pyBCrr7O8"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline_trans_translation_run2', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline_trans_translation_run2', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99hgfH86sKUu"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_trans_translation_run2', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_trans_translation_run2', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i26dxjSvIcM"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_trans_translation_run2', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_trans_translation_run2', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trpcScbAvcwK"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/pipeline2_trans_translation_run2', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/pipeline2_trans_translation_run2', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOS2yXEybIT7"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/pipeline2_trans_translation_run2', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/pipeline2_trans_translation_run2', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6eDPA0Eu0eQ"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_lstm_translation_run2_2', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline1_lstm_translation_run2_2', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAwk7pGvrnw_"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline_lstm_translation_run2_2', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Baseline_lstm_translation_run2_2', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcTejvAOrn89"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/trans_pipeline1_run2_final.txt', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/trans_pipeline1_run2_final.txt', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVsaO8yUuCz2"
      },
      "source": [
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline2_lstm_translation_run2_2', encoding = \"utf-8\") as z:\n",
        "  data = z.readlines()\n",
        "  new = []\n",
        "  for index in range(len(data)):\n",
        "    if data[index] == '\\n':\n",
        "      continue\n",
        "    \n",
        "    if data[index].split()[0] == 'PRED' and data[index].split()[1] != 'SCORE:':\n",
        "\n",
        "      new.append(data[index].split()[2:])\n",
        "\n",
        "  for index in range(len(new)):\n",
        "    new[index] = ' '.join([str(i) for i in new[index]])\n",
        "    \n",
        "with open(r'/content/drive/My Drive/DSS_Thesis_code/Pipeline2_lstm_translation_run2_2', \"w\") as o:\n",
        "  for v in new:\n",
        "    o.writelines(v + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKOsxiG9YBTI"
      },
      "source": [
        "!pip install sacrebleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_4zXbFnZOtp"
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "cwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm9xzVmhYIlv"
      },
      "source": [
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Pipeline2_lstm_translation > lstm_pipeline_final.txt\n",
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Pipeline2_trans_translation > trans_pipeline_final.txt\n",
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Baseline_lstm_translation > lstm_baseline_final.txt\n",
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Baseline_trans_translation > trans_baseline_final.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc32lSOsvrT9"
      },
      "source": [
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Pipeline1_lstm_translation > lstm_pipeline1_final.txt\n",
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Pipeline1_trans_translation > trans_pipeline1_final.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abfbRO-nSYnq"
      },
      "source": [
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Baseline_trans_translation_run2 > trans_baseline_run2_final.txt\n",
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Pipeline1_trans_translation_run2 > trans_pipeline1_run2_final.txt\n",
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Pipeline2_trans_translation_run2 > trans_pipeline2_run2_final.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFVJqzwwuLT_"
      },
      "source": [
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Baseline_lstm_translation_run2_2 > trans_baseline_run2_2_final.txt\n",
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Pipeline1_lstm_translation_run2_2 > trans_pipeline1_run2_2_final.txt\n",
        "!perl scripts/detokenize.perl -no-escape -l de -threads 16 < Pipeline2_lstm_translation_run2_2 > trans_pipeline2_run2_2_final.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC5YM3IuuY7I"
      },
      "source": [
        "!sacrebleu test.tok.clean.bpe.trg -i trans_baseline_run2_2_final.txt -m bleu ter  -b -w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRphh1-ZvGm7"
      },
      "source": [
        "!sacrebleu test_compressed.tok.clean.bpe.trg -i trans_pipeline1_run2_2_final.txt -m bleu ter  -b -w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__bsuwsWvGyd"
      },
      "source": [
        "!sacrebleu test.tok.clean.bpe.trg -i trans_pipeline2_run2_2_final.txt -m bleu ter  -b -w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og_TrNrXTHzO"
      },
      "source": [
        "!sacrebleu test_compressed.tok.clean.bpe.trg -i trans_pipeline1_run2_final.txt -m bleu ter  -b -w 4 #BLUE MST 1 RUN2 Trans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnAvCbnGTJ8e"
      },
      "source": [
        "!sacrebleu test.tok.clean.bpe.trg -i trans_pipeline2_run2_final.txt -m bleu ter  -b -w 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9aVlTXfTKAx"
      },
      "source": [
        "!sacrebleu test.tok.clean.bpe.trg -i trans_baseline_run2_final.txt -m bleu ter  -b -w 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWmc9wOqwehO"
      },
      "source": [
        "!sacrebleu test_compressed.tok.clean.bpe.trg -i lstm_pipeline1_final.txt -m bleu ter  -b -w 4 #BLEU MTS1 lstm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9zngAcQwtHS"
      },
      "source": [
        "!sacrebleu test_compressed.tok.clean.bpe.trg -i trans_pipeline1_final.txt -m bleu ter  -b -w 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoip8hU0hW9i"
      },
      "source": [
        "!sacrebleu test.tok.clean.bpe.trg -i lstm_baseline_final.txt -m bleu ter  -b -w 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez7TXDRXhIQH"
      },
      "source": [
        "!sacrebleu test.tok.clean.bpe.trg -i lstm_pipeline_final.txt -m bleu ter  -b -w 4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWOeUtZFhXEo"
      },
      "source": [
        "!sacrebleu test.tok.clean.bpe.trg -i trans_baseline_final.txt -m bleu ter -b -w 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qXcfT8xhW2x"
      },
      "source": [
        "!sacrebleu test.tok.clean.bpe.trg -i trans_pipeline_final.txt -m bleu ter  -b -w 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN-Iz-RZL1eL"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "langs = ['Trans_B2', 'Trans_B1', 'LSTM_B', 'Trans_P2', 'LSTM_P', 'Trans_P1']\n",
        "students = [2.6023,2.4522,1.2025,0.4965,0.4807,0.2236 ]\n",
        "ax.bar(langs,students)\n",
        "ax.set_ylabel('BLEU scores')\n",
        "plt.show()\n",
        "\n",
        "# Some example data to display\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_i3GVpdU4gq"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73vkyob7aCB_"
      },
      "source": [
        "LSTM_P = np.array([0.409, 0.092, 0.008])\n",
        "Trans_P1 = np.array([0.409, 0.401, 0.02])\n",
        "Trans_P2 = np.array([0.409, 0.192, 0.014])\n",
        "LSTM__B = np.array([0.249, 0.089])\n",
        "Trans_B = np.array([0.249, 0.228])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5p_evmnZqW9"
      },
      "source": [
        "plt.plot(LSTM_P, '--', color='c', label = 'LSTM Pipeline')\n",
        "plt.plot(Trans_P1, '-.', color='#008000', label = 'Transformer Pipeline 1')\n",
        "plt.plot(Trans_P2, color='b', label = 'Transformer Pipeline 2')\n",
        "plt.legend()\n",
        "plt.ylabel('Type-Token Ratio')\n",
        "plt.xticks(np.arange(1,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUOsTVxtjhtx"
      },
      "source": [
        "from scipy import stats\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q09I5mX3iahA"
      },
      "source": [
        "LSTM_P_bl = np.array([0.8535, 0.4807])\n",
        "Trans_P1_bl = np.array([2.5663, 0.02236])\n",
        "Trans_P2_bl = np.array([2.5943, 0.4965])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Mwx9aFigeI"
      },
      "source": [
        "LSTM_P_ttr = np.array([0.092, 0.008])\n",
        "Trans_P1_ttr = np.array([0.401, 0.02])\n",
        "Trans_P2_ttr = np.array([0.192, 0.014])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfpQFMcHnxQ0"
      },
      "source": [
        "bleu = np.array([0.8535, 0.4807,2.5663, 0.02236,2.5943, 0.4965])\n",
        "ttr = np.array([0.092, 0.008,0.401, 0.02,0.192, 0.014])\n",
        "ter = np.array([97.6556, 102.2522,96.8974, 101.2857, 95.5461, 100.8480])\n",
        "mattr = np.array([0.778, 0.605,0.961, 0.732, 0.74, 0.652])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A96k0H2djBFO"
      },
      "source": [
        "stats.spearmanr(bleu, ttr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq9L6WOzo0_i"
      },
      "source": [
        "stats.spearmanr(ter, ttr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlhtQZpKpYZ6"
      },
      "source": [
        "stats.spearmanr(bleu, mattr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTgCpt3_paTm"
      },
      "source": [
        "stats.spearmanr(ter, mattr)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}